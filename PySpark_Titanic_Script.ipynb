{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean, col, split, regexp_extract, when, isnan, count, create_map, lit\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/02 17:29:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create Spark Session (like a container)\n",
    "spark = SparkSession.builder.appName('PySpark with ML').getOrCreate()\n",
    "train_df = spark.read.csv('train.csv', header=True, inferSchema=True)\n",
    "test_df = spark.read.csv('test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|summary|           Survived|            Pclass|               Age|             SibSp|              Parch|             Fare|\n",
      "+-------+-------------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|  count|                891|               891|               714|               891|                891|              891|\n",
      "|   mean| 0.3838383838383838| 2.308641975308642| 29.69911764705882|0.5230078563411896|0.38159371492704824| 32.2042079685746|\n",
      "| stddev|0.48659245426485753|0.8360712409770491|14.526497332334035|1.1027434322934315| 0.8060572211299488|49.69342859718089|\n",
      "|    min|                  0|                 1|              0.42|                 0|                  0|              0.0|\n",
      "|    25%|                  0|                 2|              20.0|                 0|                  0|           7.8958|\n",
      "|    50%|                  0|                 3|              28.0|                 0|                  0|          14.4542|\n",
      "|    75%|                  1|                 3|              38.0|                 1|                  0|             31.0|\n",
      "|    max|                  1|                 3|              80.0|                 8|                  6|         512.3292|\n",
      "+-------+-------------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select('Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare').summary().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+\n",
      "|Survived|          avg(Age)|         avg(Fare)|\n",
      "+--------+------------------+------------------+\n",
      "|       1|28.343689655172415| 48.39540760233917|\n",
      "|       0| 30.62617924528302|22.117886885245877|\n",
      "+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('Survived').mean('Age', 'Fare').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+\n",
      "|Survived|  1|  2|  3|\n",
      "+--------+---+---+---+\n",
      "|       1|136| 87|119|\n",
      "|       0| 80| 97|372|\n",
      "+--------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('Survived').pivot('Pclass').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+\n",
      "|Survived|female|male|\n",
      "+--------+------+----+\n",
      "|       1|   233| 109|\n",
      "|       0|    81| 468|\n",
      "+--------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('Survived').pivot('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+---+----+---+----+\n",
      "|Survived|  0|  1|  2|  3|   4|  5|   6|\n",
      "+--------+---+---+---+---+----+---+----+\n",
      "|       1|233| 65| 40|  3|null|  1|null|\n",
      "|       0|445| 53| 40|  2|   4|  4|   1|\n",
      "+--------+---+---+---+---+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Those with smaller families had a higher chance of surviving\n",
    "train_df.groupBy('Survived').pivot('Parch').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+---+---+----+----+\n",
      "|Survived|  0|  1|  2|  3|  4|   5|   8|\n",
      "+--------+---+---+---+---+---+----+----+\n",
      "|       1|210|112| 13|  4|  3|null|null|\n",
      "|       0|398| 97| 15| 12| 15|   5|   7|\n",
      "+--------+---+---+---+---+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Those without a partner to travel with were more likely to survive\n",
    "train_df.groupBy('Survived').pivot('SibSp').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in train_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Cabin)|\n",
      "+------------+\n",
      "|         204|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(count(train_df.Cabin)).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Cabin has about 77% data missing, and Cabin and Pclass are similar, we can drop Cabin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|summary|   Fare|\n",
      "+-------+-------+\n",
      "|    50%|14.4542|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select('Fare').summary('50%').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since S is the majority of the Embarked column, we will replace the two null values with S. There are missing values in test data for Fare so we will fill in those missing values with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna({'Embarked':'S', 'Fare': 14.45})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group similar titles together and assign the average age to the missing values for that title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------+\n",
      "|   Title|count(Age)|          avg(Age)|\n",
      "+--------+----------+------------------+\n",
      "|      Mr|       398|32.368090452261306|\n",
      "|    Miss|       146|21.773972602739725|\n",
      "|     Mrs|       108|35.898148148148145|\n",
      "|  Master|        36| 4.574166666666667|\n",
      "|     Rev|         6|43.166666666666664|\n",
      "|      Dr|         6|              42.0|\n",
      "|     Col|         2|              58.0|\n",
      "|    Mlle|         2|              24.0|\n",
      "|   Major|         2|              48.5|\n",
      "|     Don|         1|              40.0|\n",
      "|Countess|         1|              33.0|\n",
      "|    Lady|         1|              48.0|\n",
      "|Jonkheer|         1|              38.0|\n",
      "|     Mme|         1|              24.0|\n",
      "|    Capt|         1|              70.0|\n",
      "|      Ms|         1|              28.0|\n",
      "|     Sir|         1|              49.0|\n",
      "+--------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.withColumn('Title', regexp_extract(train_df['Name'], '([A-Za-z]+)\\.', 1))\n",
    "train_df.groupBy('Title').agg(count('Age'), mean('Age')).sort(col('count(Age)').desc()).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 titles are Mr, Miss, and Mrs which account for most of the titles of passengers. Master is lower in count than the top three, however, the average age is much lower which could account for a different group of passengers. Thus, we will map the other titles to the top 4 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "| Title|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  Miss|             21.86|\n",
      "|Master| 4.574166666666667|\n",
      "|    Mr| 33.02272727272727|\n",
      "|   Mrs|35.981818181818184|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_dictionary = {'Mr':'Mr', 'Miss':'Miss', 'Mrs':'Mrs','Master':'Master','Rev':'Mr', 'Dr':'Mr', 'Col':'Mr', 'Mlle':'Miss', 'Major': 'Mr', 'Don':'Mr', 'Countess':'Mrs', 'Lady': 'Mrs', 'Jonkheer':'Mr','Mme':'Miss', 'Capt':'Mr','Ms':'Miss','Sir':'Mr'}\n",
    "title_map = create_map([lit(x) for x in chain(*title_dictionary.items())])\n",
    "train_df = train_df.withColumn('Title', title_map[train_df['Title']])\n",
    "train_df.groupBy('Title').mean('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_imputer(df, title, age):\n",
    "    return df.withColumn('Age', when((df['Age'].isNull()) & (df['Title'] == title), age).otherwise(df['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = age_imputer(train_df, 'Mr', 33.02)\n",
    "train_df = age_imputer(train_df, 'Miss', 21.86)\n",
    "train_df = age_imputer(train_df, 'Mrs', 35.98)\n",
    "train_df = age_imputer(train_df, 'Master', 4.57)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will create a new column named FamilySize to have a count of total members of a family using columns Parch and SibSpl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn('FamilySize', train_df['Parch'] + train_df['SibSp']).drop('Parch', 'SibSp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also dropping other columns we do not need for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('PassengerID', 'Name', 'Ticket', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+----------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|FamilySize|\n",
      "+--------+------+------+----+-------+--------+----------+\n",
      "|       0|     3|  male|22.0|   7.25|       S|         1|\n",
      "|       1|     1|female|38.0|71.2833|       C|         1|\n",
      "|       1|     3|female|26.0|  7.925|       S|         0|\n",
      "|       1|     1|female|35.0|   53.1|       S|         1|\n",
      "|       0|     3|  male|35.0|   8.05|       S|         0|\n",
      "+--------+------+------+----+-------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---+----+--------+----------+\n",
      "|Survived|Pclass|Sex|Age|Fare|Embarked|FamilySize|\n",
      "+--------+------+---+---+----+--------+----------+\n",
      "|       0|     0|  0|  0|   0|       0|         0|\n",
      "+--------+------+---+---+----+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in train_df.columns]).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first convert the 'Sex' and 'Embarked' columns from string to numeric index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+----------+------+-----------+\n",
      "|Survived|Pclass| Age|   Fare|FamilySize|SexNum|EmbarkedNum|\n",
      "+--------+------+----+-------+----------+------+-----------+\n",
      "|       0|     3|22.0|   7.25|         1|   0.0|        0.0|\n",
      "|       1|     1|38.0|71.2833|         1|   1.0|        1.0|\n",
      "|       1|     3|26.0|  7.925|         0|   1.0|        0.0|\n",
      "|       1|     1|35.0|   53.1|         1|   1.0|        0.0|\n",
      "|       0|     3|35.0|   8.05|         0|   0.0|        0.0|\n",
      "+--------+------+----+-------+----------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strInd = StringIndexer(inputCols=['Sex', 'Embarked'], outputCols=['SexNum', 'EmbarkedNum'])\n",
    "strInd_mod = strInd.fit(train_df)\n",
    "\n",
    "train_df_new = strInd_mod.transform(train_df).drop('Sex', 'Embarked')\n",
    "train_df_new.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use VectorAssembler because in scikit learn, it takes X and y in a separation matrix. Usually, y is a column vector and X is a matrix. But for Spark API, X and y has to be in a single matrix instead of two for the training data. It only accepts X in the prediction part. X should also be a vector in each row of the dataframe. We cannot directly feed the dataframe to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+\n",
      "|features                      |Survived|\n",
      "+------------------------------+--------+\n",
      "|[3.0,22.0,7.25,1.0,0.0,0.0]   |0       |\n",
      "|[1.0,38.0,71.2833,1.0,1.0,1.0]|1       |\n",
      "|[3.0,26.0,7.925,0.0,1.0,0.0]  |1       |\n",
      "|[1.0,35.0,53.1,1.0,1.0,0.0]   |1       |\n",
      "|[3.0,35.0,8.05,0.0,0.0,0.0]   |0       |\n",
      "+------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_assemble = VectorAssembler(inputCols=train_df_new.columns[1:], outputCol='features')\n",
    "train_df_new = vec_assemble.transform(train_df_new).select('features', 'Survived')\n",
    "train_df_new.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation first. Will use the test dataset later for prediction results\n",
    "train_df, validation_df = train_df_new.randomSplit([0.8, 0.2], seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+\n",
      "|features             |Survived|\n",
      "+---------------------+--------+\n",
      "|(6,[0,1],[1.0,33.02])|0       |\n",
      "|(6,[0,1],[1.0,33.02])|0       |\n",
      "|(6,[0,1],[1.0,38.0]) |0       |\n",
      "|(6,[0,1],[1.0,39.0]) |0       |\n",
      "|(6,[0,1],[1.0,40.0]) |0       |\n",
      "+---------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
